"""
è®°å¿†è¡°é€€å®šæ—¶ä»»åŠ¡è°ƒåº¦å™¨

ä½¿ç”¨ APScheduler å®ç°å®šæ—¶æ›´æ–°è®°å¿†è¡°é€€åˆ†æ•°å’Œè‡ªåŠ¨å½’æ¡£åŠŸèƒ½
"""

import logging
import os
from apscheduler.schedulers.background import BackgroundScheduler
from apscheduler.triggers.cron import CronTrigger
from app.database import SessionLocal
from app.utils.decay import (
    update_memory_decay_scores,
    auto_archive_decayed_memories,
    get_decay_statistics
)

# é…ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# åˆ›å»ºè°ƒåº¦å™¨å®ä¾‹
scheduler = BackgroundScheduler()

# ä»ç¯å¢ƒå˜é‡è¯»å–é…ç½®
DECAY_ENABLED = os.getenv("MEMORY_DECAY_ENABLED", "true").lower() == "true"
DECAY_HALF_LIFE_DAYS = int(os.getenv("MEMORY_DECAY_HALF_LIFE_DAYS", "30"))
DECAY_AUTO_ARCHIVE_THRESHOLD = float(os.getenv("MEMORY_DECAY_AUTO_ARCHIVE_THRESHOLD", "0.1"))
DECAY_UPDATE_HOUR = int(os.getenv("MEMORY_DECAY_UPDATE_HOUR", "2"))  # é»˜è®¤å‡Œæ™¨2ç‚¹
DECAY_UPDATE_MINUTE = int(os.getenv("MEMORY_DECAY_UPDATE_MINUTE", "0"))


def update_decay_job():
    """
    å®šæ—¶æ›´æ–°è®°å¿†è¡°é€€åˆ†æ•°çš„ä»»åŠ¡
    
    è¯¥ä»»åŠ¡ä¼šï¼š
    1. æ›´æ–°æ‰€æœ‰æ´»è·ƒè®°å¿†çš„è¡°é€€åˆ†æ•°
    2. è‡ªåŠ¨å½’æ¡£è¡°é€€ä¸¥é‡çš„è®°å¿†
    3. è®°å½•ç»Ÿè®¡ä¿¡æ¯
    """
    if not DECAY_ENABLED:
        logger.info("è®°å¿†è¡°é€€åŠŸèƒ½å·²ç¦ç”¨ï¼Œè·³è¿‡æ›´æ–°")
        return
    
    db = SessionLocal()
    try:
        logger.info("=" * 60)
        logger.info("å¼€å§‹æ‰§è¡Œè®°å¿†è¡°é€€æ›´æ–°ä»»åŠ¡")
        logger.info(f"é…ç½®: åŠè¡°æœŸ={DECAY_HALF_LIFE_DAYS}å¤©, å½’æ¡£é˜ˆå€¼={DECAY_AUTO_ARCHIVE_THRESHOLD}")
        
        # 1. æ›´æ–°è¡°é€€åˆ†æ•°
        updated_count = update_memory_decay_scores(
            db,
            batch_size=100,
            half_life_days=DECAY_HALF_LIFE_DAYS
        )
        logger.info(f"âœ… å·²æ›´æ–° {updated_count} æ¡è®°å¿†çš„è¡°é€€åˆ†æ•°")
        
        # 2. è‡ªåŠ¨å½’æ¡£è¡°é€€ä¸¥é‡çš„è®°å¿†
        archived_count = auto_archive_decayed_memories(
            db,
            threshold=DECAY_AUTO_ARCHIVE_THRESHOLD,
            batch_size=100
        )
        logger.info(f"âœ… å·²è‡ªåŠ¨å½’æ¡£ {archived_count} æ¡è¡°é€€è®°å¿†")
        
        # 3. è·å–ç»Ÿè®¡ä¿¡æ¯
        stats = get_decay_statistics(db)
        logger.info("ğŸ“Š è¡°é€€ç»Ÿè®¡:")
        logger.info(f"   æ€»è®°å¿†æ•°: {stats['total_memories']}")
        logger.info(f"   å¹³å‡è¡°é€€åˆ†æ•°: {stats['average_decay_score']}")
        logger.info(f"   æ–°é²œè®°å¿† (â‰¥0.7): {stats['high_decay_count']}")
        logger.info(f"   ä¸­ç­‰è¡°é€€ (0.3-0.7): {stats['medium_decay_count']}")
        logger.info(f"   ä¸¥é‡è¡°é€€ (<0.3): {stats['low_decay_count']}")
        
        logger.info("è®°å¿†è¡°é€€æ›´æ–°ä»»åŠ¡å®Œæˆ")
        logger.info("=" * 60)
        
    except Exception as e:
        logger.error(f"âŒ è®°å¿†è¡°é€€æ›´æ–°ä»»åŠ¡å¤±è´¥: {e}", exc_info=True)
    finally:
        db.close()


def start_decay_scheduler():
    """
    å¯åŠ¨è®°å¿†è¡°é€€è°ƒåº¦å™¨
    
    æ ¹æ®é…ç½®å†³å®šæ˜¯å¦å¯ç”¨è¡°é€€åŠŸèƒ½ï¼Œå¹¶è®¾ç½®å®šæ—¶ä»»åŠ¡
    """
    if not DECAY_ENABLED:
        logger.info("âš ï¸  è®°å¿†è¡°é€€åŠŸèƒ½å·²ç¦ç”¨ï¼ˆMEMORY_DECAY_ENABLED=falseï¼‰")
        return
    
    try:
        # æ·»åŠ å®šæ—¶ä»»åŠ¡ï¼šæ¯å¤©æŒ‡å®šæ—¶é—´æ‰§è¡Œ
        scheduler.add_job(
            update_decay_job,
            trigger=CronTrigger(hour=DECAY_UPDATE_HOUR, minute=DECAY_UPDATE_MINUTE),
            id='memory_decay_update',
            name='è®°å¿†è¡°é€€æ›´æ–°ä»»åŠ¡',
            replace_existing=True
        )
        
        # å¯åŠ¨è°ƒåº¦å™¨
        scheduler.start()
        
        logger.info("=" * 60)
        logger.info("ğŸš€ è®°å¿†è¡°é€€è°ƒåº¦å™¨å·²å¯åŠ¨")
        logger.info(f"â° æ›´æ–°æ—¶é—´: æ¯å¤© {DECAY_UPDATE_HOUR:02d}:{DECAY_UPDATE_MINUTE:02d}")
        logger.info(f"ğŸ“… åŠè¡°æœŸ: {DECAY_HALF_LIFE_DAYS} å¤©")
        logger.info(f"ğŸ“¦ å½’æ¡£é˜ˆå€¼: {DECAY_AUTO_ARCHIVE_THRESHOLD}")
        logger.info("=" * 60)
        
    except Exception as e:
        logger.error(f"âŒ å¯åŠ¨è®°å¿†è¡°é€€è°ƒåº¦å™¨å¤±è´¥: {e}", exc_info=True)


def stop_decay_scheduler():
    """
    åœæ­¢è®°å¿†è¡°é€€è°ƒåº¦å™¨
    """
    if scheduler.running:
        scheduler.shutdown()
        logger.info("è®°å¿†è¡°é€€è°ƒåº¦å™¨å·²åœæ­¢")


def trigger_decay_update_now():
    """
    ç«‹å³è§¦å‘ä¸€æ¬¡è¡°é€€æ›´æ–°ï¼ˆç”¨äºæ‰‹åŠ¨è§¦å‘æˆ–æµ‹è¯•ï¼‰
    
    è¿”å›:
        æ˜¯å¦æˆåŠŸè§¦å‘
    """
    if not DECAY_ENABLED:
        logger.warning("è®°å¿†è¡°é€€åŠŸèƒ½å·²ç¦ç”¨ï¼Œæ— æ³•è§¦å‘æ›´æ–°")
        return False
    
    try:
        logger.info("æ‰‹åŠ¨è§¦å‘è®°å¿†è¡°é€€æ›´æ–°...")
        update_decay_job()
        return True
    except Exception as e:
        logger.error(f"æ‰‹åŠ¨è§¦å‘è¡°é€€æ›´æ–°å¤±è´¥: {e}", exc_info=True)
        return False


def get_scheduler_status() -> dict:
    """
    è·å–è°ƒåº¦å™¨çŠ¶æ€ä¿¡æ¯
    
    è¿”å›:
        è°ƒåº¦å™¨çŠ¶æ€å­—å…¸
    """
    if not DECAY_ENABLED:
        return {
            "enabled": False,
            "running": False,
            "message": "è®°å¿†è¡°é€€åŠŸèƒ½å·²ç¦ç”¨"
        }
    
    jobs = scheduler.get_jobs()
    next_run = None
    
    if jobs:
        job = jobs[0]
        next_run = job.next_run_time.isoformat() if job.next_run_time else None
    
    return {
        "enabled": True,
        "running": scheduler.running,
        "next_run_time": next_run,
        "update_schedule": f"{DECAY_UPDATE_HOUR:02d}:{DECAY_UPDATE_MINUTE:02d}",
        "half_life_days": DECAY_HALF_LIFE_DAYS,
        "archive_threshold": DECAY_AUTO_ARCHIVE_THRESHOLD,
        "jobs_count": len(jobs)
    }